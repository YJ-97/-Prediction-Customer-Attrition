{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../datasets/BankChurners.csv')\n",
    "list = ['Attrition_Flag', 'Total_Trans_Ct', 'Total_Trans_Amt', 'Total_Revolving_Bal', 'Total_Ct_Chng_Q4_Q1', 'Contacts_Count_12_mon', 'Total_Relationship_Count', 'Months_Inactive_12_mon', 'Months_on_book']\n",
    "data = data[list]\n",
    "#data = data.iloc[:,1:21]\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category : [0 1]\n",
      "classes : ['Attrited Customer' 'Existing Customer']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "object_columns = data.select_dtypes('object').columns\n",
    "\n",
    "for i in object_columns:\n",
    "\n",
    "    lb = LabelEncoder()\n",
    "    lb.fit(data[i])\n",
    "    data[i] = lb.transform(data[i])\n",
    "    \n",
    "    print(f'category : {np.unique(data[i])}\\nclasses : {lb.classes_}\\n')\n",
    "\n",
    "input = data.iloc[:,1:]\n",
    "target = data.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8101, 8) (2026, 8) (8101, 2) (2026, 2)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(input, target, random_state=42, test_size=0.2)\n",
    "y_train= to_categorical(y_train)\n",
    "y_test= to_categorical(y_test)\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_3 (Batc  (None, 8)                32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 512)               4608      \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 179,266\n",
      "Trainable params: 179,250\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def metric_precision(y_true,y_pred): \n",
    " TP=tf.reduce_sum(y_true*tf.round(y_pred))\n",
    " TN=tf.reduce_sum((1-y_true)*(1-tf.round(y_pred)))\n",
    " FP=tf.reduce_sum((1-y_true)*tf.round(y_pred))\n",
    " FN=tf.reduce_sum(y_true*(1-tf.round(y_pred)))\n",
    " precision=TP/(TP+FP)\n",
    " return precision\n",
    "\n",
    "def metric_recall(y_true,y_pred): \n",
    " TP=tf.reduce_sum(y_true*tf.round(y_pred))\n",
    " TN=tf.reduce_sum((1-y_true)*(1-tf.round(y_pred)))\n",
    " FP=tf.reduce_sum((1-y_true)*tf.round(y_pred))\n",
    " FN=tf.reduce_sum(y_true*(1-tf.round(y_pred)))\n",
    " recall=TP/(TP+FN)\n",
    " return recall\n",
    "\n",
    "#F1-score    \n",
    "def metric_F1score(y_true,y_pred): \n",
    " TP=tf.reduce_sum(y_true*tf.round(y_pred))\n",
    " TN=tf.reduce_sum((1-y_true)*(1-tf.round(y_pred)))\n",
    " FP=tf.reduce_sum((1-y_true)*tf.round(y_pred))\n",
    " FN=tf.reduce_sum(y_true*(1-tf.round(y_pred)))\n",
    " precision=TP/(TP+FP)\n",
    " recall=TP/(TP+FN)\n",
    " F1score=2*precision*recall/(precision+recall)\n",
    " return F1score\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(keras.Input(shape=(8,)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "\t loss='binary_crossentropy',\n",
    "\t metrics=['accuracy',\n",
    "\t \t\tmetric_precision,\n",
    "\t \t\tmetric_recall,\n",
    "\t \t\tmetric_F1score])\n",
    "            \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.22836, saving model to ./model\\01-0.228358.hdf5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.22836 to 0.19865, saving model to ./model\\02-0.198648.hdf5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.19865 to 0.19354, saving model to ./model\\03-0.193538.hdf5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.19354 to 0.18764, saving model to ./model\\04-0.187641.hdf5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.18764 to 0.17971, saving model to ./model\\05-0.179711.hdf5\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.17971\n",
      "\n",
      "Epoch 7: val_loss improved from 0.17971 to 0.17816, saving model to ./model\\07-0.178156.hdf5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.17816 to 0.17769, saving model to ./model\\08-0.177685.hdf5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.17769 to 0.17249, saving model to ./model\\09-0.172493.hdf5\n",
      "\n",
      "Epoch 10: val_loss improved from 0.17249 to 0.17073, saving model to ./model\\10-0.170729.hdf5\n",
      "\n",
      "Epoch 11: val_loss improved from 0.17073 to 0.16966, saving model to ./model\\11-0.169658.hdf5\n",
      "\n",
      "Epoch 12: val_loss improved from 0.16966 to 0.16876, saving model to ./model\\12-0.168758.hdf5\n",
      "\n",
      "Epoch 13: val_loss improved from 0.16876 to 0.16628, saving model to ./model\\13-0.166283.hdf5\n",
      "\n",
      "Epoch 14: val_loss improved from 0.16628 to 0.16132, saving model to ./model\\14-0.161318.hdf5\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.16132\n",
      "\n",
      "Epoch 16: val_loss improved from 0.16132 to 0.15903, saving model to ./model\\16-0.159031.hdf5\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.15903\n",
      "\n",
      "Epoch 18: val_loss improved from 0.15903 to 0.15242, saving model to ./model\\18-0.152422.hdf5\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.15242\n",
      "\n",
      "Epoch 20: val_loss improved from 0.15242 to 0.15084, saving model to ./model\\20-0.150835.hdf5\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.15084\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.15084\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.15084\n",
      "\n",
      "Epoch 24: val_loss improved from 0.15084 to 0.15016, saving model to ./model\\24-0.150164.hdf5\n",
      "\n",
      "Epoch 25: val_loss improved from 0.15016 to 0.14974, saving model to ./model\\25-0.149736.hdf5\n",
      "\n",
      "Epoch 26: val_loss improved from 0.14974 to 0.14678, saving model to ./model\\26-0.146776.hdf5\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.14678\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.14678\n",
      "\n",
      "Epoch 29: val_loss improved from 0.14678 to 0.14459, saving model to ./model\\29-0.144587.hdf5\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.14459\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.14459\n",
      "\n",
      "Epoch 32: val_loss improved from 0.14459 to 0.14375, saving model to ./model\\32-0.143748.hdf5\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.14375\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.14375\n",
      "\n",
      "Epoch 35: val_loss improved from 0.14375 to 0.14324, saving model to ./model\\35-0.143239.hdf5\n",
      "\n",
      "Epoch 36: val_loss improved from 0.14324 to 0.14082, saving model to ./model\\36-0.140816.hdf5\n",
      "\n",
      "Epoch 37: val_loss improved from 0.14082 to 0.13560, saving model to ./model\\37-0.135600.hdf5\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.13560\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.13560\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.13560\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.13560\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.13560\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.13560\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.13560\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.13560\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.13560\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.13560\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.13560\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.13560\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.13560\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.13560\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.13560\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.13560\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.13560\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.13560\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.13560\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.13560\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.1419 - accuracy: 0.9497 - metric_precision: 0.9502 - metric_recall: 0.9502 - metric_F1score: 0.9502\n",
      "\n",
      " Test Accuracy: 0.9497\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "\n",
    "modelpath = './model/{epoch:02d}-{val_loss:4f}.hdf5'\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=100,\n",
    "batch_size=32, verbose=0, callbacks=[early_stopping_callback, checkpointer])\n",
    "\n",
    "print('\\n Test Accuracy: %.4f' % (model.evaluate(x_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 테스트 셋의 오차\n",
    "y_vloss = history.history['val_loss']\n",
    "\n",
    "# 학습셋의 오차\n",
    "y_loss = history.history[\"loss\"]\n",
    "\n",
    "# 그래프로 표현\n",
    "x_len = np.arange(len(y_loss))\n",
    "plt.plot(x_len, y_vloss, marker=\".\", c=\"red\", label=\"Testset_loss\")\n",
    "plt.plot(x_len, y_loss, marker=\".\", c=\"blue\", label=\"Trainset_loss\")\n",
    "\n",
    "# 그래프에 그리드를 주고 레이블을 표시\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_13 (Bat  (None, 8)                32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 256)               2304      \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_38 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,634\n",
      "Trainable params: 45,618\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def metric_precision(y_true,y_pred): \n",
    " TP=tf.reduce_sum(y_true*tf.round(y_pred))\n",
    " TN=tf.reduce_sum((1-y_true)*(1-tf.round(y_pred)))\n",
    " FP=tf.reduce_sum((1-y_true)*tf.round(y_pred))\n",
    " FN=tf.reduce_sum(y_true*(1-tf.round(y_pred)))\n",
    " precision=TP/(TP+FP)\n",
    " return precision\n",
    "\n",
    "def metric_recall(y_true,y_pred): \n",
    " TP=tf.reduce_sum(y_true*tf.round(y_pred))\n",
    " TN=tf.reduce_sum((1-y_true)*(1-tf.round(y_pred)))\n",
    " FP=tf.reduce_sum((1-y_true)*tf.round(y_pred))\n",
    " FN=tf.reduce_sum(y_true*(1-tf.round(y_pred)))\n",
    " recall=TP/(TP+FN)\n",
    " return recall\n",
    "\n",
    "#F1-score    \n",
    "def metric_F1score(y_true,y_pred): \n",
    " TP=tf.reduce_sum(y_true*tf.round(y_pred))\n",
    " TN=tf.reduce_sum((1-y_true)*(1-tf.round(y_pred)))\n",
    " FP=tf.reduce_sum((1-y_true)*tf.round(y_pred))\n",
    " FN=tf.reduce_sum(y_true*(1-tf.round(y_pred)))\n",
    " precision=TP/(TP+FP)\n",
    " recall=TP/(TP+FN)\n",
    " F1score=2*precision*recall/(precision+recall)\n",
    " return F1score\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(keras.Input(shape=(8,)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "\t loss='binary_crossentropy',\n",
    "\t metrics=['accuracy',\n",
    "\t \t\tmetric_precision,\n",
    "\t \t\tmetric_recall,\n",
    "\t \t\tmetric_F1score])\n",
    "            \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.23693, saving model to ./model\\01-0.236932.hdf5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.23693 to 0.20405, saving model to ./model\\02-0.204049.hdf5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.20405 to 0.19249, saving model to ./model\\03-0.192488.hdf5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.19249 to 0.18656, saving model to ./model\\04-0.186556.hdf5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.18656 to 0.18376, saving model to ./model\\05-0.183759.hdf5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.18376 to 0.18035, saving model to ./model\\06-0.180352.hdf5\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.18035\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.18035\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.18035\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.18035\n",
      "\n",
      "Epoch 11: val_loss improved from 0.18035 to 0.17362, saving model to ./model\\11-0.173623.hdf5\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.17362\n",
      "\n",
      "Epoch 13: val_loss improved from 0.17362 to 0.16974, saving model to ./model\\13-0.169742.hdf5\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.16974\n",
      "\n",
      "Epoch 15: val_loss improved from 0.16974 to 0.16580, saving model to ./model\\15-0.165797.hdf5\n",
      "\n",
      "Epoch 16: val_loss improved from 0.16580 to 0.15984, saving model to ./model\\16-0.159844.hdf5\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.15984\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.15984\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.15984\n",
      "\n",
      "Epoch 20: val_loss improved from 0.15984 to 0.15932, saving model to ./model\\20-0.159321.hdf5\n",
      "\n",
      "Epoch 21: val_loss improved from 0.15932 to 0.15749, saving model to ./model\\21-0.157491.hdf5\n",
      "\n",
      "Epoch 22: val_loss improved from 0.15749 to 0.15737, saving model to ./model\\22-0.157372.hdf5\n",
      "\n",
      "Epoch 23: val_loss improved from 0.15737 to 0.15688, saving model to ./model\\23-0.156883.hdf5\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.15688\n",
      "\n",
      "Epoch 25: val_loss improved from 0.15688 to 0.15347, saving model to ./model\\25-0.153466.hdf5\n",
      "\n",
      "Epoch 26: val_loss improved from 0.15347 to 0.15209, saving model to ./model\\26-0.152090.hdf5\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.15209\n",
      "\n",
      "Epoch 28: val_loss improved from 0.15209 to 0.15010, saving model to ./model\\28-0.150102.hdf5\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.15010\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.15010\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.15010\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.15010\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.15010\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.15010\n",
      "\n",
      "Epoch 35: val_loss improved from 0.15010 to 0.14968, saving model to ./model\\35-0.149677.hdf5\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.14968\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.14968\n",
      "\n",
      "Epoch 38: val_loss improved from 0.14968 to 0.14928, saving model to ./model\\38-0.149279.hdf5\n",
      "\n",
      "Epoch 39: val_loss improved from 0.14928 to 0.14504, saving model to ./model\\39-0.145036.hdf5\n",
      "\n",
      "Epoch 40: val_loss improved from 0.14504 to 0.14361, saving model to ./model\\40-0.143607.hdf5\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.14361\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.14361\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.14361\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.14361\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.14361\n",
      "\n",
      "Epoch 46: val_loss improved from 0.14361 to 0.13899, saving model to ./model\\46-0.138989.hdf5\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.13899\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.13899\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.13899\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.13899\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.13899\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.13899\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.13899\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.13899\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.13899\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.13899\n",
      "\n",
      "Epoch 57: val_loss improved from 0.13899 to 0.13792, saving model to ./model\\57-0.137921.hdf5\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.13792\n",
      "\n",
      "Epoch 59: val_loss improved from 0.13792 to 0.13749, saving model to ./model\\59-0.137485.hdf5\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.13749\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.13749\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.13749\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.13749\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.13749\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.13749\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.13749\n",
      "\n",
      "Epoch 67: val_loss improved from 0.13749 to 0.13722, saving model to ./model\\67-0.137217.hdf5\n",
      "\n",
      "Epoch 68: val_loss improved from 0.13722 to 0.13674, saving model to ./model\\68-0.136744.hdf5\n",
      "\n",
      "Epoch 69: val_loss improved from 0.13674 to 0.13482, saving model to ./model\\69-0.134821.hdf5\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.13482\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.13482\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.13482\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.13482\n",
      "\n",
      "Epoch 74: val_loss improved from 0.13482 to 0.13351, saving model to ./model\\74-0.133509.hdf5\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.13351\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.13351\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.13351\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.13351\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.13351\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.13351\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.13351\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.13351\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.13351\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.13351\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.13351\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.13351\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.13351\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.13351\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.13351\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.13351\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.13351\n",
      "\n",
      "Epoch 92: val_loss improved from 0.13351 to 0.13310, saving model to ./model\\92-0.133101.hdf5\n",
      "\n",
      "Epoch 93: val_loss improved from 0.13310 to 0.13308, saving model to ./model\\93-0.133075.hdf5\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.13308\n",
      "\n",
      "Epoch 95: val_loss improved from 0.13308 to 0.13155, saving model to ./model\\95-0.131552.hdf5\n",
      "\n",
      "Epoch 96: val_loss improved from 0.13155 to 0.13153, saving model to ./model\\96-0.131533.hdf5\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.13153\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.13153\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.13153\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.13153\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.1333 - accuracy: 0.9501 - metric_precision: 0.9507 - metric_recall: 0.9507 - metric_F1score: 0.9507\n",
      "\n",
      " Test Accuracy: 0.9501\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "\n",
    "modelpath = './model/{epoch:02d}-{val_loss:4f}.hdf5'\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=100,\n",
    "batch_size=32, verbose=0, callbacks=[early_stopping_callback, checkpointer])\n",
    "\n",
    "print('\\n Test Accuracy: %.4f' % (model.evaluate(x_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dc0be73154618f58c692376fe46a96bfb7aea1860fce4c5a4dc26143c6655afc"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
